{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Important Libraries**\n"
      ],
      "metadata": {
        "id": "CvafrxKM-ncm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import heapq\n",
        "from collections import Counter\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "My0YSSU3-oCm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0-Load File**"
      ],
      "metadata": {
        "id": "s-94PnJT-7JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Open and read the file content as a single string\n",
        "with open('/content/Test_text_file.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Convert the string into a list of characters\n",
        "content_array = list(content)\n",
        "\n",
        "# Display the array\n",
        "\n"
      ],
      "metadata": {
        "id": "HY3PzWzH_C-e"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-Character Probability Estimation**\n",
        "\n"
      ],
      "metadata": {
        "id": "bBzOT6YXize7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming content_array is a list or array-like object\n",
        "text = pd.DataFrame(content_array)\n",
        "\n",
        "# Calculate value counts\n",
        "text_valuecounts = text.value_counts()\n",
        "\n",
        "# Calculate probabilities\n",
        "text_prob = text_valuecounts / text.size\n",
        "\n",
        "\n",
        "print(sum(text_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuOE9Q8L-a80",
        "outputId": "c1aece20-cdb2-4d4e-97d3-bf1cf3980a0e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9999999999999997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-Entropy Calculation**\n",
        "\n"
      ],
      "metadata": {
        "id": "uanHax9Zi4yh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the entropy based on the symbol probabilities calculated in\n",
        "step one. (0.5 point)"
      ],
      "metadata": {
        "id": "gK4MOuASnOHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_entropy (probabilities):\n",
        "    entropy = 0\n",
        "    for probability in probabilities :\n",
        "        entropy= entropy+ probability * math.log(1/probability,2)\n",
        "    return entropy\n",
        "entropy =  calc_entropy(text_prob)\n",
        "entropy"
      ],
      "metadata": {
        "id": "Bspz8ig0i-Tw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e59041-2224-4e2a-adf8-61b47f11c681"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.2570105647380725"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3-Fixed-Length Code Bit Calculation and Efficiency**"
      ],
      "metadata": {
        "id": "3Ttjt_CajCZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the number of bits/symbol required to construct a fixed length\n",
        "code, and calculate the efficiency of that code. (0.5 point)"
      ],
      "metadata": {
        "id": "21UnaGW_nVQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_fixedLength_CODE(NO_symbols) :\n",
        "     num_OF_bits = math.log(NO_symbols,2)\n",
        "     return num_OF_bits\n",
        "def calc_efficiency(no_ofBits_perSample,entropy):\n",
        "    efficency =   entropy /no_ofBits_perSample\n",
        "    return efficency\n",
        "\n",
        "\n",
        "num_of_fixed_bits = calc_fixedLength_CODE(33)\n",
        "print (num_of_fixed_bits , \" is the number of bits per char \")\n",
        "efficency = calc_efficiency(num_of_fixed_bits,entropy)\n",
        "efficency"
      ],
      "metadata": {
        "id": "nYYmqiWIjKFB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b88b23f-a7b7-4f4e-8e60-e21bbc144589"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.044394119358453  is the number of bits per char \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8439091918693061"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4-Custom Huffman Encoder Implementation**"
      ],
      "metadata": {
        "id": "nsaRbqjIjLCp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the Huffman encoder function (donâ€™t use the Huffman\n",
        "encoder function in Matlab, develop your own function), and encode\n",
        "the file characters into a stream of zeros and ones. Show in a table\n",
        "each character in the source text file and its corresponding Huffman\n",
        "code. (1.5 points)"
      ],
      "metadata": {
        "id": "zw9UNHVsne4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probabilities(file_path):\n",
        "    # Read the file and count character occurrences\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    # Count each character's occurrences\n",
        "    char_count = Counter(text)\n",
        "\n",
        "    # Calculate the total number of characters in the text\n",
        "    total_chars = sum(char_count.values())\n",
        "\n",
        "    # Calculate the probability for each character\n",
        "    probabilities = {char: count / total_chars for char, count in char_count.items()}\n",
        "\n",
        "    return probabilities\n",
        "\n",
        "class TreeNode:\n",
        "    def __init__(self, character, probability):  # Corrected __init__ with double underscores\n",
        "        self.character = character\n",
        "        self.probability = probability\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "    def __lt__(self, other):  # Corrected __lt__ with double underscores\n",
        "        return self.probability < other.probability\n",
        "\n",
        "def build_huffman_tree(probabilities):\n",
        "    heap = [TreeNode(char, prob) for char, prob in probabilities.items()]\n",
        "    heapq.heapify(heap)\n",
        "\n",
        "    while len(heap) > 1:\n",
        "        left = heapq.heappop(heap)\n",
        "        right = heapq.heappop(heap)\n",
        "        merged = TreeNode(None, left.probability + right.probability)\n",
        "        merged.left = left\n",
        "        merged.right = right\n",
        "        heapq.heappush(heap, merged)\n",
        "\n",
        "    return heap[0]\n",
        "\n",
        "def generate_code_map(node, current_code, code_map):\n",
        "    if node is not None:\n",
        "        if node.character is not None:\n",
        "            code_map[node.character] = current_code\n",
        "        generate_code_map(node.left, current_code + \"0\", code_map)\n",
        "        generate_code_map(node.right, current_code + \"1\", code_map)\n",
        "\n",
        "def huffman_encode(file_path):\n",
        "    probabilities = calculate_probabilities(file_path)\n",
        "    root = build_huffman_tree(probabilities)\n",
        "    code_map = {}\n",
        "    generate_code_map(root, \"\", code_map)\n",
        "    with open(file_path, 'r') as file:\n",
        "        text = file.read()\n",
        "    encoded_text = ''.join(code_map[char] for char in text)\n",
        "    return code_map, encoded_text\n",
        "\n",
        "def show_code_table(code_map):\n",
        "    print(\"Character | Huffman Code\")\n",
        "    print(\"-----------------------\")\n",
        "    for char, code in code_map.items():\n",
        "        print(f\"    {char}     |   {code}\")\n",
        "\n",
        "\n",
        "\n",
        "file_path = 'Test_text_file.txt'\n",
        "code_map, encoded_text = huffman_encode(file_path)\n",
        "show_code_table(code_map)\n",
        "print(\"\\nEncoded Text:\", encoded_text)\n"
      ],
      "metadata": {
        "id": "X5XlhgcbjP7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b24f1f8-597c-4fa2-f037-72ff5ba49285"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character | Huffman Code\n",
            "-----------------------\n",
            "    d     |   0000\n",
            "    -     |   000100\n",
            "    b     |   000101\n",
            "    c     |   00011\n",
            "    e     |   001\n",
            "    s     |   0100\n",
            "    f     |   010100\n",
            "    y     |   0101010\n",
            "    w     |   0101011\n",
            "    g     |   010110\n",
            "    ,     |   0101110\n",
            "    .     |   01011110\n",
            "    z     |   010111110\n",
            "    )     |   010111111\n",
            "    r     |   0110\n",
            "    i     |   0111\n",
            "    o     |   1000\n",
            "    n     |   1001\n",
            "          |   101\n",
            "    t     |   1100\n",
            "    a     |   1101\n",
            "    p     |   11100\n",
            "    u     |   111010\n",
            "    v     |   1110110\n",
            "    x     |   11101110\n",
            "    (     |   111011110\n",
            "    k     |   11101111100\n",
            "    j     |   11101111101\n",
            "    /     |   11101111110\n",
            "    q     |   11101111111\n",
            "    l     |   11110\n",
            "    m     |   111110\n",
            "    h     |   111111\n",
            "\n",
            "Encoded Text: 0111100110111001111110111010010111100110111100001011001011101011101101100110001110110001111101010000001000111000011001100011111011011100011110001001000100000101110101000010000101000111000100100011111010011001100011001110010100000111010110011111001101111101011110001100010000011101001100100001101100011110001001101111011110000011100000001011111110101001000111101110101100011110001001101011101001011110001101000111001000010000100001010101001000011010100001110101101111100001000001011101100100001011100011011011001010011111001111100110000101100100101111011110110011101110010111111101001111110111001111010000101010011110010101101011101101010001111001010110111100011010101011011100000010001011101100100001011110010000101011001011010111011111101110011110011101010001110010110101111011110111001101010111111010111010111011001000010111101011000111111100111010111110011110010101101011110111110111101001001100101110110101000111100101011011110001101010100001001000000010111010001111101111100101011000100011001011111101100010110101111001101110011111101011110101110011111100110111100011010001110010000100001000010100000010001110000110011000111110110111000111100010010001000001011101010000100001011110011010110110111111000111000010110101111100011101011010010111100101011010101001000111101110101100011110001001101011101001010001011000110011111110101010011110001111011100111000101111100011011101100100001010100011111111011100111100010101110101110110010000101100011100001011011011100001010010101111001101110110100011111101000010000100000001001111010001000111001011111101101100110010010110010111010110001110011100100001000010000101110010001011100111111001101010101101110000001111100101010101110111100111001111001110010000101011110010000011101100010001111001011111000111010110100101111001010110101110101100001111111101111100001000111100111010011000101011110101110011111100110111100011010001110010000100001000010100000010001110000110011000111110110111000111100010010001000001011101010000100001011111000111010110100101111001010110101110110010000101000011100000010111100011010000001100101000100011110010101101010001111011001101110111110010010001010001010011010010101000101000010001111000111111011000111110010101010111011110011100111100111001000010111001000101111110100001100011011000011000000111100111010110010101010101000111100101011011110001000100000101110110010000101110001101101100101001111100111010001000111100010010100010111010111010100101010101100111110111101011101010010101011000110010010110110111110011101011111000100001011100100010111111010000110001101110011111111011001101110001010111000101110001101101100101001111100111110010100010111011001000001000101111010111001111110110100011101001011011111110111011010001110001111101110001100011111110011001010001111110110001101110110011101111100101010010001110100101000111000111011000101100111100101011010100010110001100111111101110011111100110100001110000001011110011010110110111111000111000010110101111100011101011010010111100101011010111011001000010111001111110011011111101101011110011011110011011100111111101111000110100000011001010001000111100101011001011101010111110010101110100101010011111110000101011100110111001111111101110010111001111110011010001110001111101110011110001111011100111110001010101011000010100101110011111100110111100011010001110010000100001000010100011100010010001111101001100110001100111001010000111000000101011101001010100111010000101010011001101100111000111110111110111100101010101111101000010101100101101010001110001111101110011010110001000010101010110111110011111110111001111110011011000110011111100101101010100110011011100001000100100001010000010011001111110010001001101011011001010001110001001000111110100110011000110011100101000011100000010111111000111001111111000000001000101111010100111101110110000110010100011111101100011010100001110010110000101001011110111111111101011011001110001111100110111000111111011000110101000111111110111010111101101110001111000100110111011001000010101100101001011111100011101010011101001100011111100011001110010101100010100111010111101100010010111010110001101110111110010010001011110001100010100001100111000010000010111010111101001000111100101011010111011010001011101010000100010001001100110111000111100010011011110011011011101010010101010110011111011110101110101001011101101000111000111110111110001011000011011111011111010111110110000100010011010000111011011011001000110010000101111110100000010101111111000110111100110101011101011100100010100111101101101111101110101101110000110111011001000010111101101101111100111000011011100001101110011111100110100101010001010000100011110001111110110001100100101000100101100001010010111001111110011011110001101000111001000010000100001010000111000000101010010001111011101011000111100010011010111100110111101101101011001111000111010010010101100011101111101010101011100001101111000001010100000110011001110101100111100001000101110101011110010001110000110111001000011011011100011110010101101010100011110010101101111000100010000010111011001000011101111110000011101011011111000010000010111011001000010111001110111010100011110101000010100010111101011100111111001101010001111111101110101111011011100011110001001101110110010000101011001010010111111000111010100111010011000111111000110011100101011000101001110101111011000100101000000111111010001001010011000110110111000011010011110111000011001111101111000110011100101111100111100100111010110011101011111011011100011110001001101111000010110010100100001101111101101100100011001101100001010010111001111110011011110001101000111001000010000100001010001110001001000111110100110011000110011100101000011100000001011101010011110110001100110110001110101100111000010110010100100001101111100111100101011010100011111010011001100011001110010101001100110111000010001001000010100000100110011111100100010011010110110010111111000111001111111000000001000101110101000000101001110001111100001101110011111100110101000111010110100101110101000111000111101100111001111001010101011111010000101011001011010100011100011111011100111100011110111001111100010101001011110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLKY736ZGRz9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5-Huffman Decoder Implementation and Validation**"
      ],
      "metadata": {
        "id": "X7rkLlurjQ3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the Huffman decoder function, and write the decoded\n",
        "stream of characters back to a separate text file, and make sure that it\n",
        "matches the original text file. (1.5 points)"
      ],
      "metadata": {
        "id": "6-62Chfmn2rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def huffman_decode(encoded_text):\n",
        "    probabilities = calculate_probabilities(file_path)\n",
        "    root = build_huffman_tree(probabilities)\n",
        "    decoded_text = \"\"\n",
        "    current_node = root\n",
        "    for bit in encoded_text:\n",
        "        if bit == \"0\":\n",
        "            current_node = current_node.left\n",
        "        else:\n",
        "            current_node = current_node.right\n",
        "\n",
        "        if current_node.left is None and current_node.right is None:\n",
        "            decoded_text += current_node.character\n",
        "            current_node = root\n",
        "\n",
        "    return decoded_text\n",
        "decoded_text = huffman_decode(encoded_text)\n",
        "print(\"\\nDecoded Text:\", decoded_text)"
      ],
      "metadata": {
        "id": "W4QLfUt6jWNM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c85d2fe4-16c3-4cf6-9fb9-b9a9e027cdbd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Decoded Text: in this paper, a novel decorrelation-based concurrent digital predistortion (dpd) solution is proposed for dual-band transmitters (tx) employing a single wideband power amplifier (pa), and utilizing just a single feedback receiver path. the proposed decorrelation-based parameter learning solution is both flexible and simple, and operates in a closed-loop manner, opposed to the widely applied indirect learning architecture. the proposed decorrelation-based learning and dpd processing can also be effectively applied to more ordinary single-band transmissions, as well as generalized to more than two transmit bands. through a comprehensive analysis covering both the dpd parameter learning and the main path processing, it is shown that the complexity of the proposed concurrent dpd is substantially lower compared with the other state-of-the-art concurrent dpd methods. extensive set of quantitative simulation and rf measurement results are also presented, using a base-station pa as well as a commercial lte-advanced mobile pa, to evaluate and validate the effectiveness of the proposed dpd solution in various real world scenarios, incorporating single-band/dual-band tx cases. the simulation and rf measurement results demonstrate excellent linearization performance of the proposed concurrent dpd, even outperforming current state-of-the-art methods, despite the significantly lower complexity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6-Huffman Code Efficiency Calculation**"
      ],
      "metadata": {
        "id": "NdY5ClZvjWhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the efficiency of the Huffman code. (0.5 point)"
      ],
      "metadata": {
        "id": "-76G6_TRn7JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_average_length(code_map, probabilities):\n",
        "    average_length = 0\n",
        "    for char, code in code_map.items():\n",
        "        probability = probabilities[char]\n",
        "        average_length += probability * len(code)\n",
        "    return average_length\n",
        "average_length = calculate_average_length(code_map,text_prob)\n",
        "huffman_efficiency =  calc_efficiency(average_length,entropy)\n",
        "average_length\n",
        "huffman_efficiency*100\n"
      ],
      "metadata": {
        "id": "O7G0KBMejcuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "513118e1-7beb-4b6e-f831-20f4e1f7db94"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99.54768209347522"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7-Shannon-Fano Encoder and Decoder Implementation**"
      ],
      "metadata": {
        "id": "SoKCllKPjdSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the Shannon-Fano code (encoder) for the same\n",
        "data. (2 points)"
      ],
      "metadata": {
        "id": "gBFKOn56oBRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Shannon_Fano_encoder(Symbols_prob, prefix=\"\"):\n",
        "    # Convert Symbols_prob values to float to avoid type errors\n",
        "    Symbols_prob = Symbols_prob.astype(float)\n",
        "\n",
        "    # Base case: if there's only one unique symbol, return it with its prefix as code\n",
        "    if len(Symbols_prob) == 1:\n",
        "        return pd.Series({Symbols_prob.index[0]: prefix})\n",
        "    elif len(Symbols_prob) == 2:\n",
        "        # If only two unique symbols are left, assign them directly\n",
        "        return pd.Series({Symbols_prob.index[0]: prefix + \"0\", Symbols_prob.index[1]: prefix + \"1\"})\n",
        "\n",
        "    # Calculate the total probability sum for splitting\n",
        "    total_prob_sum = Symbols_prob.sum()\n",
        "\n",
        "    # Find the split index to divide Symbols into two groups as equally as possible\n",
        "    index = 0\n",
        "    c_weight_n = 0\n",
        "    c_weight_n_1 = -1\n",
        "\n",
        "    for i in range(Symbols_prob.size):\n",
        "        c_weight_n_1 = c_weight_n\n",
        "        c_weight_n += Symbols_prob.iloc[i]\n",
        "\n",
        "        if c_weight_n >= total_prob_sum / 2:\n",
        "            if c_weight_n - total_prob_sum / 2 < total_prob_sum / 2 - c_weight_n_1:\n",
        "                index = i\n",
        "            else:\n",
        "                index = i - 1\n",
        "            break\n",
        "\n",
        "    # Split Symbols_prob into left and right halves\n",
        "    left_prob = Symbols_prob.iloc[:index + 1]\n",
        "    right_prob = Symbols_prob.iloc[index + 1:]\n",
        "\n",
        "    # Recursively encode the left and right halves\n",
        "    left_codes = Shannon_Fano_encoder(left_prob, prefix + \"0\")\n",
        "    right_codes = Shannon_Fano_encoder(right_prob, prefix + \"1\")\n",
        "\n",
        "    # Combine the left and right halves into a single Series\n",
        "    return pd.concat([left_codes, right_codes])\n",
        "\n",
        "codes = Shannon_Fano_encoder(text_prob)\n",
        "print(\"Shannon-Fano Codes:\")\n",
        "print(codes)\n",
        "\n"
      ],
      "metadata": {
        "id": "WktYQb-Kjji5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cd9f59f-1550-4aa2-9b3e-c2fdf0ff08e3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shannon-Fano Codes:\n",
            "             000\n",
            "e            001\n",
            "t           0100\n",
            "a           0101\n",
            "n           0110\n",
            "o           0111\n",
            "i           1000\n",
            "r           1001\n",
            "s           1010\n",
            "d          10110\n",
            "l          10111\n",
            "p          11000\n",
            "c          11001\n",
            "h          11010\n",
            "m          11011\n",
            "u         111000\n",
            "g         111001\n",
            "f         111010\n",
            "b         111011\n",
            "-         111100\n",
            "v        1111010\n",
            "w        1111011\n",
            ",        1111100\n",
            "y        1111101\n",
            "x       11111100\n",
            ".       11111101\n",
            "z      111111100\n",
            "(      111111101\n",
            ")     1111111100\n",
            "q     1111111101\n",
            "k    11111111100\n",
            "/    11111111101\n",
            "j     1111111111\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encode the text file"
      ],
      "metadata": {
        "id": "tKONPioNBGCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_text(text, codes):\n",
        "    encoded_text = \"\"\n",
        "\n",
        "    # Loop through each character in the text and find its corresponding code\n",
        "    for i in text:\n",
        "        # Append the code for the symbol i from the codes Series\n",
        "        encoded_text+=(codes.loc[i][0])\n",
        "\n",
        "    return encoded_text\n",
        "encoded_text = encode_text(content_array, codes)\n",
        "encoded_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "kzCzIPPmBPpx",
        "outputId": "9136e503-11b2-4d1f-a9af-6a7ae1bff353"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-60264d723bde>:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  encoded_text+=(codes.loc[i][0])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10000110000010011010100010100001100001011100000110011111100000010100001100111111101000110111000101100011100101111001100100110111010101001000011101101111001110110101101000110110000110010111011011001111000100110010010110010000010110100011100110000100010110111000110001001001101101000101001000111100101001000011101100001111111011011011000101101111111100000101001111011111100001001000011101100001000101000011000100101111100001111010001101100001110100111100100010110111000010110111111100111011010101101011000001001001010101101010110111000010001000011001101000011111110101001111110011111111000000011101111000101110111111110110000110111001000010100010101000011011100110111001000111101110001011000111101101010110101100001100001111111011001100100001011101111000101111000111010100000110010001111111011100001011111111100111110000001010110101100001110000100100010111100011111110010000110111001000111111111111100010100100000010100010101000011011100110111001000111010001001101101110110101110011111111110000010010011100100110001111010001100100011000010101001101011111101000010011010001000110001001011111000011110100011011000010110001110010111100110010011011101010100100001110110111100111011010110100011011000011000010110010101110110010100001100100010111001010110010110100001101110010001010011110111111000010010000111011000010001010000111011011101001101000011101010111001111111001000111011101110010000101011010110000101010001101111000101110011111100000010101101011000001111100000110010101010000110100001000011000001010001100110111011110100011011011110010111011101111100000011011010101100110001100111111000000111110001100001111010001101100000100011100001001101000100011110111000101100011011111111010000101110001100010111100000110110000100001101011010001001001110010100000101110010101100101101000011011100100001011001110011101010000100001110010100111000100100111111101000010011010001000110001001011111000011110100011011000010110001110010111100110010011011101010100100001110110111100111011010110100011011000010111001010110010110100001101110010000101011010110000101101100010110000110001001011111001001101010101000011011100100011001010101100000101101111010011100011101100100000111101011101000111001010010001111010001101111111101000010111000110001011110000011011000001000111000110110111100100100001111001101101000011001011001111110100010101000011011100110111001111100111011010101101011000001001001010101101010110111000101010101000011101101010111110000001011010000111101100110111101110000101101000011100100101100011001010110111100011111110000110110000010001110001101101111001001000010011010010101100000100111101101110000100100101010110101011011100001000001110110101011010110101011111101000010011010100101111110001110011101000001010001100101111101111000100100111010001011010101000111101000100001010110010110111111110110101000101000011001011111110100011001100001101110010001110110111010011010000010011010001000101101100010110000110000101100101011101100101000011001000101110010101100101101000011011100100001010110101100000100110100010001101101011000011000011000010101001101000011000100101111100100110101010100001101110011111100000100001000001000101000010101101001111111011011000001001101001010100000010011010001000110010111110111100010111001111111001000010011111010000111111010000010011010001000110001001011111000011110100011011000011001011101101100111100010011001001011001000001011011000101100001000101000010101110001110111010010001010110010010000101101111011111111010001011101111111011001100100011001011111011110000101100100110110000111101110000100110100000100110100010000111010011010001100100010100100010101000011111000111111010111100010011010001111100010110010100000110010111011011001111000100110010010110010000010110110001011000011011001010011010011110110101011111101000001111111000100001011010101000111101000100010100010100000011111101000011111111011110000101011001001000010001010100100011110100010001010100011011111000101110101010010000111011000001010110101100001001111010000110110010101101011100010010011101100101100100000100100110101110001011101001010000010110010010000101101111010011100011000100100110100010110010000110110111110000011100010101000011011100100001010001110110101101000111110010100100010101001000011101100001100001010000101101000011110110011011110111000010110100000101000110010111110111101100110011100110000101101110001011101000011111000101101101111010010101101100100110110000110110111111011100010111001000110000101111110000001000111000001111101001011011111100001010100001000010101101011000011110100101101111000101100101010000100001001101000100000111101011101000111001010010001111010001011000110101010000011111101000001001101000100011000100101111100001111010001101100001011011000101100001010011110111111000010010000111011000010000110000111101001011001100001111110001010000100100101011011100011110110111100110111101100001010110010010110010110011000011110101111100000100001101100101111001110000111100101010100100001101110010001010100001101110011011100111110011101101010110101101111111110110110111000010110111111100111011010101101011000001001111110000011001010110100011010111111010000100110100010001010100011011111000101110101010010000111011000001010110101100001001111010000110110010101101011100010010011101100101100100000100100110101110001011101001010000101100011101101110110101001001001010101000010000011111110011001001101111011100101100100000101111000011000101011001100011111110001010100100001110110000110000011001111010011110011101101010110110010010000111111010000010011010001000110001001011111000011110100011011000011001011101101100111100010011001001011001000001011011000101101111100000001111101000101100000111111000010011000001100111101001111001110111000011011100100011001111000100110010010110010000010100100010101000011111000111111010111100010011010001111100010110010100000110110010100110100111101101010111110000010110001101011000100001000010000100110100010001010100011100101101000111010100011001010101100100101111111101000101110111111101100110010001100101111101111000101110011111110010000100111110111111101'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement the Shannon-Fano code (dencoder) for the same\n",
        "data. (2 points)"
      ],
      "metadata": {
        "id": "yKs5qNkAAPRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shannon-Fano Decoder Function\n",
        "def Shannon_Fano_decoder(encoded_text, codes):\n",
        "    # Create a reverse mapping dictionary for decoding\n",
        "    reverse_codes = {}\n",
        "\n",
        "    # Populate reverse_codes by handling tuple or non-tuple cases separately\n",
        "    for symbol, code in codes.items():\n",
        "        if isinstance(code, tuple):\n",
        "            reverse_codes[code[0]] = symbol  # Use the first element if code is a tuple\n",
        "        else:\n",
        "            reverse_codes[code] = symbol     # Use code directly if it's not a tuple\n",
        "\n",
        "    # Initialize variables for decoded text and the current sequence of bits\n",
        "    decoded_text = \"\"\n",
        "    current_bits = \"\"\n",
        "\n",
        "    # Decode the text by accumulating bits and checking for matches in reverse_codes\n",
        "    for bit in encoded_text:\n",
        "        current_bits += bit\n",
        "        if current_bits in reverse_codes:\n",
        "            decoded_text += ''.join(reverse_codes[current_bits])  # Convert tuple to string and append\n",
        "            current_bits = \"\"  # Reset current_bits after a successful match\n",
        "\n",
        "    return decoded_text\n",
        "\n",
        "# Decode the encoded text\n",
        "decoded_text = Shannon_Fano_decoder(encoded_text, codes)\n",
        "\n",
        "# Display Shannon-Fano decoded text\n",
        "print(\"Decoded Text:\\n\", decoded_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNf6rFkBATkq",
        "outputId": "2aca8989-f213-4ea5-e866-c5e6207b0ff4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded Text:\n",
            " in this paper, a novel decorrelation-based concurrent digital predistortion (dpd) solution is proposed for dual-band transmitters (tx) employing a single wideband power amplifier (pa), and utilizing just a single feedback receiver path. the proposed decorrelation-based parameter learning solution is both flexible and simple, and operates in a closed-loop manner, opposed to the widely applied indirect learning architecture. the proposed decorrelation-based learning and dpd processing can also be effectively applied to more ordinary single-band transmissions, as well as generalized to more than two transmit bands. through a comprehensive analysis covering both the dpd parameter learning and the main path processing, it is shown that the complexity of the proposed concurrent dpd is substantially lower compared with the other state-of-the-art concurrent dpd methods. extensive set of quantitative simulation and rf measurement results are also presented, using a base-station pa as well as a commercial lte-advanced mobile pa, to evaluate and validate the effectiveness of the proposed dpd solution in various real world scenarios, incorporating single-band/dual-band tx cases. the simulation and rf measurement results demonstrate excellent linearization performance of the proposed concurrent dpd, even outperforming current state-of-the-art methods, despite the significantly lower complexity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Shannon-Fano code (efficiency)"
      ],
      "metadata": {
        "id": "KXQjAuS2Efaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def average_code_length(Symbols_prob, codes):\n",
        "    # Calculate length of each code\n",
        "    code_lengths = codes.str.len()\n",
        "\n",
        "    # Multiply each probability by the corresponding code length\n",
        "    weighted_lengths = Symbols_prob * code_lengths\n",
        "\n",
        "    # Return the (average code length)\n",
        "    return weighted_lengths.sum()\n",
        "codes = Shannon_Fano_encoder(text_prob)\n",
        "average_length = average_code_length(text_prob, codes)\n",
        "print(\"Average Code Length:\", average_length)\n",
        "\n",
        "\n",
        "print(\"efficiency: \",entropy/average_length*100)"
      ],
      "metadata": {
        "id": "6tWI-76kjo1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "187b5482-11ae-4c22-dcbf-e0d7a5aa5a90"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Code Length: 4.27920227920228\n",
            "efficiency:  99.48140534108278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**8-Efficiency Comparison: Shannon-Fano vs. Huffman Codes**"
      ],
      "metadata": {
        "id": "bNUlBZj3jkBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare the performance (efficiency) of Shannon-Fano code with\n",
        "Huffman code. (0.5 point)"
      ],
      "metadata": {
        "id": "ODD45OHGoFpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparison Function\n",
        "def compare_coding_methods(file_path, text_prob, entropy):\n",
        "    # Calculate Fixed-Length Coding Metrics\n",
        "    num_of_symbols = len(text_prob)  # Number of unique symbols\n",
        "    fixed_bits_per_symbol = calc_fixedLength_CODE(num_of_symbols)\n",
        "    fixed_avg_length = fixed_bits_per_symbol  # Same for fixed-length coding\n",
        "    fixed_efficiency = calc_efficiency(fixed_avg_length, entropy)\n",
        "\n",
        "    # Huffman Coding\n",
        "    huffman_code_map, _ = huffman_encode(file_path)\n",
        "    huffman_avg_length = calculate_average_length(huffman_code_map, text_prob)\n",
        "    huffman_efficiency = calc_efficiency(huffman_avg_length, entropy)\n",
        "\n",
        "    # Shannon-Fano Coding\n",
        "    shannon_fano_codes = Shannon_Fano_encoder(text_prob)\n",
        "    shannon_fano_avg_length = average_code_length(text_prob, shannon_fano_codes)\n",
        "    shannon_fano_efficiency = calc_efficiency(shannon_fano_avg_length, entropy)\n",
        "\n",
        "    # Display Results\n",
        "    print(\"\\nComparison of Coding Methods:\")\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "    print(f\"{'Method':<15} {'Average Length':<20} {'Efficiency (%)':<20}\")\n",
        "    print(\"-----------------------------------------------------------\")\n",
        "    print(f\"{'Fixed-Length':<15} {fixed_avg_length:<20.4f} {fixed_efficiency * 100:<20.2f}\")\n",
        "    print(f\"{'Huffman':<15} {huffman_avg_length:<20.4f} {huffman_efficiency * 100:<20.2f}\")\n",
        "    print(f\"{'Shannon-Fano':<15} {shannon_fano_avg_length:<20.4f} {shannon_fano_efficiency * 100:<20.2f}\")\n",
        "\n",
        "# Call the comparison function\n",
        "compare_coding_methods('Test_text_file.txt', text_prob, entropy)\n"
      ],
      "metadata": {
        "id": "fkPA33BRN4sH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6333e3e5-887b-4ef0-b1e2-f9236d116668"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison of Coding Methods:\n",
            "-----------------------------------------------------------\n",
            "Method          Average Length       Efficiency (%)      \n",
            "-----------------------------------------------------------\n",
            "Fixed-Length    5.0444               84.39               \n",
            "Huffman         4.2764               99.55               \n",
            "Shannon-Fano    4.2792               99.48               \n"
          ]
        }
      ]
    }
  ]
}